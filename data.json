{
    "llamacpp": [
        {
            "repo": "ggml-org/llama.cpp/releases/download/b6178",
            "filename": "llama-b6178-bin-win-cuda-12.4-x64.zip",
            "version": "b6178-CUDA",
            "gpu": "Nvidia独显",
            "require_cuda": true
        },
        {
            "repo": "ggml-org/llama.cpp/releases/download/b6178",
            "filename": "llama-b6178-bin-win-hip-radeon-x64.zip",
            "version": "b6178-HIP",
            "gpu": "大部分AMD独显",
            "require_cuda": false
        },
        {
            "repo": "ggml-org/llama.cpp/releases/download/b6178",
            "filename": "llama-b6178-bin-macos-arm64.zip",
            "version": "b6178-Apple-M",
            "gpu": "苹果电脑M系列核显",
            "require_cuda": false
        },
        {
            "repo": "PiDanShouRouZhouXD/Sakura_Launcher_GUI/releases/download/v0.0.3-alpha",
            "filename": "llama-b3534-bin-win-rocm-avx512-x64.zip",
            "version": "b3534-ROCm-780m",
            "gpu": "部分AMD核显（不推荐）",
            "require_cuda": false
        },
        {
            "repo": "ggml-org/llama.cpp/releases/download/b6178",
            "filename": "llama-b6178-bin-win-vulkan-x64.zip",
            "version": "b6178-Vulkan",
            "gpu": "通用（不推荐）",
            "require_cuda": false
        }
    ],
    "sakura": [
        {
            "repo": "SakuraLLM/Sakura-GalTransl-7B-v3.7",
            "filename": "Sakura-Galtransl-7B-v3.7-IQ4_XS.gguf",
            "sha256": "8f515bf4769f279a7fcf43e57446455a9d4de7f65b1bc9eddee76717e1ff7919",
            "minimal_gpu_memory_gib": 8,
            "size": 4.25,
            "recommended_np": {
                "8": 2,
                "10": 4,
                "12": 12,
                "16": 16,
                "24": 16
            },
            "base_model_hf": "Qwen/Qwen2.5-7B",
            "bpw": 4.25,
            "config_cache": {
                "hidden_size": 4096,
                "num_attention_heads": 32,
                "num_key_value_heads": 32,
                "num_hidden_layers": 32,
                "parameters": 7721324544.0
            }
        },
        {
            "repo": "Sakura-14B-Qwen2.5-v1.0-GGUF",
            "filename": "sakura-14b-qwen2.5-v1.0-iq4xs.gguf",
            "sha256": "34af88f99c113418d0665d3ceede767c9a12040c9e7c4bb5e87cdb1b1e06e94a",
            "minimal_gpu_memory_gib": 10,
            "size": 8.19,
            "recommended_np": {
                "10": 4,
                "12": 12,
                "16": 16,
                "24": 16
            },
            "base_model_hf": "Qwen/Qwen2.5-14B",
            "bpw": 4.25,
            "config_cache": {
                "hidden_size": 5120,
                "num_attention_heads": 40,
                "num_key_value_heads": 8,
                "num_hidden_layers": 48,
                "parameters": 14770033664.0
            }
        },
        {
            "repo": "Sakura-14B-Qwen2.5-v1.0-GGUF",
            "filename": "sakura-14b-qwen2.5-v1.0-q4km.gguf",
            "sha256": "c87697cd9c7898464426cb7a1ec5e220755affaa08096766e8d20de1853c2063",
            "minimal_gpu_memory_gib": 10,
            "size": 8.99,
            "recommended_np": {
                "10": 1,
                "12": 6,
                "16": 16,
                "24": 16
            },
            "base_model_hf": "Qwen/Qwen2.5-14B",
            "bpw": 4.85,
            "config_cache": {
                "hidden_size": 5120,
                "num_attention_heads": 40,
                "num_key_value_heads": 8,
                "num_hidden_layers": 48,
                "parameters": 14770033664.0
            }
        },
        {
            "repo": "Sakura-14B-Qwen2beta-v0.9.2-GGUF",
            "filename": "sakura-14b-qwen2beta-v0.9.2-iq4xs.gguf",
            "sha256": "254a7e97e5e2a5daa371145e55bb2b0a0a789615dab2d4316189ba089a3ced67",
            "minimal_gpu_memory_gib": 12,
            "size": 7.91,
            "recommended_np": {
                "12": 1,
                "16": 6,
                "24": 8
            },
            "base_model_hf": "Qwen/Qwen1.5-14B",
            "bpw": 4.25,
            "config_cache": {
                "hidden_size": 5120,
                "num_attention_heads": 40,
                "num_key_value_heads": 40,
                "num_hidden_layers": 40,
                "parameters": 14167290880.0
            }
        },
        {
            "repo": "Sakura-14B-Qwen2beta-v0.9.2-GGUF",
            "filename": "sakura-14b-qwen2beta-v0.9.2-q4km.gguf",
            "sha256": "8bae1ae35b7327fa7c3a8f3ae495b81a071847d560837de2025e1554364001a5",
            "minimal_gpu_memory_gib": 12,
            "size": 9.19,
            "recommended_np": {
                "12": 1,
                "16": 6,
                "24": 8
            },
            "base_model_hf": "Qwen/Qwen1.5-14B",
            "bpw": 4.85,
            "config_cache": {
                "hidden_size": 5120,
                "num_attention_heads": 40,
                "num_key_value_heads": 40,
                "num_hidden_layers": 40,
                "parameters": 14167290880.0
            }
        }
    ]
}
